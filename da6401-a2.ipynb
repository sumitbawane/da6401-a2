{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11380447,"sourceType":"datasetVersion","datasetId":7125598}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nprint(torch.cuda.is_available())\nprint(torch.cuda.get_device_name(0))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:02:55.536064Z","iopub.execute_input":"2025-04-19T06:02:55.536276Z","iopub.status.idle":"2025-04-19T06:02:59.433692Z","shell.execute_reply.started":"2025-04-19T06:02:55.536250Z","shell.execute_reply":"2025-04-19T06:02:59.432937Z"}},"outputs":[{"name":"stdout","text":"True\nTesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\ndata_path = '/kaggle/input/inaturalist/inaturalist_12K/train'\ndata_path_test='/kaggle/input/inaturalist/inaturalist_12K/val'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T13:44:34.324372Z","iopub.execute_input":"2025-04-19T13:44:34.324635Z","iopub.status.idle":"2025-04-19T13:44:34.328670Z","shell.execute_reply.started":"2025-04-19T13:44:34.324615Z","shell.execute_reply":"2025-04-19T13:44:34.327883Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import wandb\nwandb.login(key='9f6e625b6a4825fa64c9ba29384c657072eb3b12')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:03:05.731070Z","iopub.execute_input":"2025-04-19T06:03:05.731309Z","iopub.status.idle":"2025-04-19T06:03:14.089808Z","shell.execute_reply.started":"2025-04-19T06:03:05.731293Z","shell.execute_reply":"2025-04-19T06:03:14.089229Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m049\u001b[0m (\u001b[33mcs24m049-iit-m\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from torch import nn\nfrom torch.nn import functional as F\n#from PP_data import preprocess_data, show_images\n\n\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes=10, input_channels=3, kernel_size=[], no_kernels=[], fc1_size=512, conv_activation='ReLU', use_batch_norm=True,dropout=0.5):\n        \n        super(SimpleCNN, self).__init__()\n        self.conv_activation = conv_activation\n        self.fc1_size = fc1_size\n        self.kernel_size = kernel_size\n        self.no_kernels = no_kernels\n        self.input_channels = input_channels\n        self.use_batch_norm = use_batch_norm  \n        self.dropout=dropout  # Dropout probability\n        # Flag to enable/disable Batch Normalization\n        # Define convolutional layers with optional Batch Normalization\n        \n        self.conv1 = nn.Conv2d(input_channels, no_kernels[0], kernel_size=kernel_size[0], stride=1, padding=kernel_size[0] // 2)\n        self.bn1 = nn.BatchNorm2d(no_kernels[0]) if use_batch_norm else None  # Optional Batch Norm\n        self.conv2 = nn.Conv2d(no_kernels[0], no_kernels[1], kernel_size=kernel_size[1], stride=1, padding=kernel_size[1] // 2)\n        self.bn2 = nn.BatchNorm2d(no_kernels[1]) if use_batch_norm else None\n        self.conv3 = nn.Conv2d(no_kernels[1], no_kernels[2], kernel_size=kernel_size[2], stride=1, padding=kernel_size[2] // 2)\n        self.bn3 = nn.BatchNorm2d(no_kernels[2]) if use_batch_norm else None\n        self.conv4 = nn.Conv2d(no_kernels[2], no_kernels[3], kernel_size=kernel_size[3], stride=1, padding=kernel_size[3] // 2)\n        self.bn4 = nn.BatchNorm2d(no_kernels[3]) if use_batch_norm else None\n        self.conv5 = nn.Conv2d(no_kernels[3], no_kernels[4], kernel_size=kernel_size[4], stride=1, padding=kernel_size[4] // 2)\n        self.bn5 = nn.BatchNorm2d(no_kernels[4]) if use_batch_norm else None\n\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(no_kernels[4] * 7 * 7, fc1_size)\n        self.fc2 = nn.Linear(fc1_size, num_classes)\n        \n        self.dropout_layer=nn.Dropout(p=self.dropout) if self.dropout>0 else None# Optional Dropout\n\n    def forward(self, x):\n        x = self.pool(self.apply_batch_norm(self.conv1(x), self.bn1))  # Apply Batch Norm if enabled\n        x = self.pool(self.apply_batch_norm(self.conv2(x), self.bn2))\n        x = self.pool(self.apply_batch_norm(self.conv3(x), self.bn3))\n        x = self.pool(self.apply_batch_norm(self.conv4(x), self.bn4))\n        x = self.pool(self.apply_batch_norm(self.conv5(x), self.bn5))\n        x = x.view(-1, self.no_kernels[4] * 7 * 7)  # Flatten the tensor\n        x = self.activation(self.fc1(x))\n        if self.dropout_layer is not None:\n            x=self.dropout_layer(x)  # Apply Dropout\n        x = self.fc2(x)\n        return x\n\n    def apply_batch_norm(self, x, bn_layer):\n        if self.use_batch_norm and bn_layer is not None:\n            return self.activation(bn_layer(x))  # Apply Batch Norm and activation\n        else:\n            return self.activation(x)  # Skip Batch Norm and apply activation\n\n    def activation(self, x):\n        if self.conv_activation == 'ReLU':\n            return F.relu(x)\n        elif self.conv_activation == 'Sigmoid':\n            return F.sigmoid(x)\n        elif self.conv_activation == 'Tanh':\n            return F.tanh(x)\n        elif self.conv_activation == 'GELU':\n            return F.gelu(x)\n        elif self.conv_activation == 'SiLU':\n            return F.silu(x)\n        elif self.conv_activation == 'Mish':\n            return F.mish(x)\n        elif self.conv_activation == 'ELU':\n            return F.elu(x)\n        elif self.conv_activation == 'SELU':\n            return F.selu(x)\n        elif self.conv_activation == 'LeakyReLU':\n            return F.leaky_relu(x)\n        else:\n            raise ValueError(\"Invalid activation function specified\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T13:45:02.853794Z","iopub.execute_input":"2025-04-19T13:45:02.854335Z","iopub.status.idle":"2025-04-19T13:45:02.866217Z","shell.execute_reply.started":"2025-04-19T13:45:02.854309Z","shell.execute_reply":"2025-04-19T13:45:02.865380Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport wandb\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch import nn\n#from cnn import SimpleCNN\nimport torch.amp as amp\nimport os\nwandb._service_wait = 60\n\n\ndef train():\n    # Initialize wandb\n    wandb.init()\n    config = wandb.config  # Access sweep parameters\n    \n    # Set device (use GPU if available)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    scaler = amp.GradScaler(enabled=device.type == 'cuda')\n    \n    # Set a meaningful name for the run\n    wandb.run.name = (\n    f\"base_filter_size_{config.base_filter}_\"\n    f\"filter_strategy_{config.filter_strategy}_\"\n    f\"kernel_{'_'.join(map(str, config.kernel_sizes))}_\"\n    f\"activation_{config.activation}_batchnorm_{config.batch_norm}_\"\n    f\"dropout_{config.dropout}_fcsize_{config.fc_size}_epochs_{config.epochs}_\"\n    f\"augmentation_{config.data_augmentation}_lr_{config.learning_rate:.1e}_\"\n    f\"batchsize_{config.batch_size}\"\n    )\n    base_filter = config.base_filter  # Base filter size for the first layer\n    filters=[]\n    if config['filter_strategy'] == 'same':\n        filters = [base_filter] * 5\n    elif config['filter_strategy'] == 'doubling':\n       filters = [base_filter * (2 ** i) for i in range(5)]\n    elif config['filter_strategy'] == 'halving':\n        filters = [base_filter * (2 ** i) for i in reversed(range(5))]\n\n    # Extract parameters from wandb config\n    no_kernels =filters\n    kernel_size = config.kernel_sizes\n    activation = config.activation\n    batch_norm = config.batch_norm\n    dropout = config.dropout\n    fc_size = config.fc_size\n    learning_rate = config.learning_rate\n    batch_size = config.batch_size\n    data_augmentation = config.data_augmentation\n    epochs = config.epochs\n    val_split = 0.2  # 20% of data for validation\n\n    # Initialize the model\n    model = SimpleCNN(\n        num_classes=10,\n        kernel_size=kernel_size,\n        no_kernels=no_kernels,\n        fc1_size=fc_size,\n        conv_activation=activation,\n        use_batch_norm=batch_norm,\n        dropout=dropout\n    )\n    \n    #model=nn.DataParallel(model)  # Use DataParallel for multi-GPU training if available\n    model=model.to(device)  # Move model to the appropriate device\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n\n    if config.optimizer_type == 'Adam':\n        optimizer =optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n    elif config.optimizer_type == 'Nadam':\n        optimizer = optim.NAdam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n\n    # Load and split the dataset into training and validation sets\n    dataset = datasets.ImageFolder(\n        root=data_path,\n        transform=get_transforms(data_augmentation, is_training=True)\n    )\n    \n    # Calculate split sizes\n    dataset_size = len(dataset)\n    val_size = int(val_split * dataset_size)\n    train_size = dataset_size - val_size\n    \n    # Split the dataset\n    train_dataset, val_dataset = random_split(\n        dataset, [train_size, val_size], \n        generator=torch.Generator().manual_seed(42)  # For reproducibility\n    )\n    \n    # Update validation set transforms (no augmentation for validation)\n    val_dataset.dataset.transform = get_transforms(False, is_training=False)\n    \n    # Create data loaders\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=batch_size, \n        shuffle=True, \n        pin_memory=True, \n        num_workers=4\n    )\n    \n    val_loader = DataLoader(\n        val_dataset, \n        batch_size=batch_size, \n        shuffle=False,  # No need to shuffle validation data\n        pin_memory=True, \n        num_workers=4\n    )\n\n    # Training loop\n    best_val_accuracy = 0\n    for epoch in range(epochs):\n        # Training phase\n        model.train()\n        train_loss, train_accuracy = run_epoch(model, train_loader, criterion, optimizer, device,scaler, is_training=True)\n        \n        # Validation phase\n        model.eval()  # Set model to evaluation mode\n        with torch.no_grad():  # Disable gradient calculation for validation\n            val_loss, val_accuracy = run_epoch(model, val_loader, criterion, optimizer, device,scaler,is_training=False)\n        \n        # Save best model\n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            torch.save(model.state_dict(), f\"best_model_{wandb.run.id}.pth\")\n\n        # Log metrics to wandb\n        wandb.log({\n            'epoch': epoch + 1,\n            'train_loss': train_loss,\n            'train_acc': train_accuracy,\n            'val_loss': val_loss,\n            'val_acc': val_accuracy\n        })\n        \n        print(f\"Epoch [{epoch + 1}/{epochs}], \"\n              f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n    \n    # Log final best validation accuracy and hyperparameters\n    wandb.log({\n        'best_val_acc': best_val_accuracy,\n        'batch_size': batch_size,\n        'activation': config.activation,\n        'batch_norm': config.batch_norm,\n        'dropout': config.dropout,\n        'fc_size': config.fc_size,\n        'learning_rate': config.learning_rate,\n        'data_augmentation': config.data_augmentation,\n        'epochs': config.epochs,\n        'base_filter': config.base_filter,\n        'filter_strategy': config.filter_strategy,\n        'kernel_sizes': config.kernel_sizes\n    })\n    \n    # Update the sweep metric\n    wandb.run.summary[\"val_acc\"] = best_val_accuracy\n\n\ndef run_epoch(model, dataloader, criterion, optimizer, device, scaler,is_training=True):\n    \"\"\"Run one epoch of training or validation.\"\"\"\n    total_loss = 0\n    total = 0\n    correct = 0\n    \n    for images, labels in dataloader:\n        images, labels = images.to(device), labels.to(device)\n        \n         # Forward pass with autocast for mixed precision\n        with amp.autocast(device_type=device.type,enabled= scaler.is_enabled() and is_training):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n        \n        # Backward pass and optimization (only during training)\n        if is_training:\n            optimizer.zero_grad()\n            # Use scaler for mixed precision gradient scaling\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        \n        # Calculate accuracy\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        # Accumulate loss\n        total_loss += loss.item() * images.size(0)\n    \n    # Calculate average loss and accuracy\n    avg_loss = total_loss / total\n    accuracy = 100 * correct / total\n    \n    return avg_loss, accuracy\n\n\ndef get_transforms(data_augmentation, is_training=True):\n    \"\"\"Get the appropriate transforms based on whether we're training and using augmentation.\"\"\"\n    if is_training and data_augmentation:\n        return transforms.Compose([\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomRotation(degrees=15),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    else:\n        return transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n\nsweep_config = {\n    'method': 'bayes',  # Optimization method: 'grid', 'random', or 'bayes'\n    'metric': {'name': 'val_acc', 'goal': 'maximize'},\n    'parameters': {\n        # strategy for filter size\n        'filter_strategy': {'values': ['same', 'doubling', 'halving']},\n        #base filter size\n        'base_filter': {'values': [32,64]},\n        \n        # Kernel sizes for each layer\n        'kernel_sizes': {'values': [[3, 3, 5, 5, 7], [5, 5, 7, 7, 3], [3, 5, 7, 5, 3],[3,3,3,3,3],[5,5,5,5,5]]},\n        'optimizer_type': {'values': ['Adam', 'Nadam']},\n        # Activation function\n        'activation': {'values': ['ReLU', 'GELU', 'SiLU', 'Mish']},\n\n        # Batch normalization\n        'batch_norm': {'values': [True, False]},\n\n        # Dropout\n        'dropout': {'values': [0.0, 0.2, 0.3]},\n\n        # Fully connected layer size\n        'fc_size': {'values': [256, 512]},\n\n        # Learning rate\n        'learning_rate': {\"distribution\": \"log_uniform_values\", \"min\": 1e-5, \"max\": 1e-3},\n\n        # Batch size\n        'batch_size': {'values': [32, 64]},\n\n        # Data augmentation\n        'data_augmentation': {'values': [True, False]},\n\n        # Number of epochs\n        'epochs': {'values': [10,15,20]}\n    }\n}\n\nif __name__ == \"__main__\":\n    wandb.login()\n    sweep_id = wandb.sweep(sweep_config, project=\"da6401 a2\")\n    wandb.agent(sweep_id, train, count=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:31:19.392781Z","iopub.execute_input":"2025-04-18T19:31:19.393059Z","iopub.status.idle":"2025-04-18T19:33:39.224141Z","shell.execute_reply.started":"2025-04-18T19:31:19.393039Z","shell.execute_reply":"2025-04-18T19:33:39.220479Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: abnvkgmf\nSweep URL: https://wandb.ai/cs24m049-iit-m/da6401%20a2%20/sweeps/abnvkgmf\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dx5no7bq with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbase_filter: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_strategy: halving\n\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_sizes: [5, 5, 7, 7, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007713339180941757\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer_type: Nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_193129-dx5no7bq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m049-iit-m/da6401%20a2%20/runs/dx5no7bq' target=\"_blank\">vital-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m049-iit-m/da6401%20a2%20' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m049-iit-m/da6401%20a2%20/sweeps/abnvkgmf' target=\"_blank\">https://wandb.ai/cs24m049-iit-m/da6401%20a2%20/sweeps/abnvkgmf</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m049-iit-m/da6401%20a2%20' target=\"_blank\">https://wandb.ai/cs24m049-iit-m/da6401%20a2%20</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m049-iit-m/da6401%20a2%20/sweeps/abnvkgmf' target=\"_blank\">https://wandb.ai/cs24m049-iit-m/da6401%20a2%20/sweeps/abnvkgmf</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m049-iit-m/da6401%20a2%20/runs/dx5no7bq' target=\"_blank\">https://wandb.ai/cs24m049-iit-m/da6401%20a2%20/runs/dx5no7bq</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torchvision import models\nfrom torch.utils.data import DataLoader, random_split\nimport torch.optim as optim\nimport wandb\n\n# Init W&B\n#wandb.init(project=\"finetune_inaturalist\", name=\"efficientnetv2_finetune\")\n\n# Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Data transforms\ndef get_transforms(is_train=True):\n    if is_train:\n        return transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.RandomHorizontalFlip(),\n            transforms.ColorJitter(0.3, 0.3, 0.3, 0.1),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n        ])\n    else:\n        return transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n        ])\n\n# Load dataset\ndataset = datasets.ImageFolder(data_path, transform=get_transforms(is_train=True))\nval_size = int(0.2 * len(dataset))\ntrain_size = len(dataset) - val_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\nval_ds.dataset.transform = get_transforms(is_train=False)\n\ntrain_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=4)\n\n# Load EfficientNetV2 pre-trained\nmodel = models.efficientnet_v2_s(weights=\"EfficientNet_V2_S_Weights.DEFAULT\")\n\n# Modify final layer\nnum_features = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(num_features, 10)\n\n# Freeze all layers first\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Strategy: unfreeze last N layers\nN = 20\nfor param in list(model.parameters())[-N:]:\n    param.requires_grad = True\n\nmodel.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n\n# Training + Validation loop\ndef run_epoch(model, dataloader, train=False):\n    model.train() if train else model.eval()\n    running_loss, correct, total = 0.0, 0, 0\n    \n    for images, labels in dataloader:\n        images, labels = images.to(device), labels.to(device)\n        \n        if train:\n            optimizer.zero_grad()\n        \n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        \n        if train:\n            loss.backward()\n            optimizer.step()\n        \n        running_loss += loss.item() * images.size(0)\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n        \n    return running_loss / total, 100 * correct / total\n\n# Training loop\nbest_val_acc = 0\nfor epoch in range(10):\n    train_loss, train_acc = run_epoch(model, train_loader, train=True)\n    val_loss, val_acc = run_epoch(model, val_loader, train=False)\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), \"best_efficientnetv2.pth\")\n    \n    print(f\"Epoch {epoch+1}: Train Acc={train_acc:.2f}%, Val Acc={val_acc:.2f}%\")\n\n#wandb.run.summary[\"best_val_acc\"] = best_val_acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:44:48.911147Z","iopub.execute_input":"2025-04-19T07:44:48.911902Z","iopub.status.idle":"2025-04-19T07:54:05.480051Z","shell.execute_reply.started":"2025-04-19T07:44:48.911847Z","shell.execute_reply":"2025-04-19T07:54:05.478956Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n100%|██████████| 82.7M/82.7M [00:00<00:00, 107MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc=51.60%, Val Acc=69.53%\nEpoch 2: Train Acc=69.41%, Val Acc=74.64%\nEpoch 3: Train Acc=73.78%, Val Acc=75.64%\nEpoch 4: Train Acc=76.08%, Val Acc=76.99%\nEpoch 5: Train Acc=77.11%, Val Acc=77.94%\nEpoch 6: Train Acc=78.64%, Val Acc=78.34%\nEpoch 7: Train Acc=80.95%, Val Acc=78.59%\nEpoch 8: Train Acc=82.30%, Val Acc=80.19%\nEpoch 9: Train Acc=83.61%, Val Acc=79.39%\nEpoch 10: Train Acc=85.24%, Val Acc=79.54%\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torch.amp as amp\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image, ImageDraw, ImageFont\nimport wandb\n\n# Set your data paths\ndata_path = data_path  # Replace with your actual path\ntest_data_path = data_path_test  # Replace with your actual path\n\n# Best configuration from the sweep\nbest_config = {\n    'base_filter': 64,\n    'filter_strategy': 'doubling',\n    'kernel_sizes': [3, 5, 7, 5, 3],\n    'activation': 'ReLU',\n    'batch_norm': True,\n    'dropout': 0.2,\n    'fc_size': 512,\n    'learning_rate': 3.3e-5,\n    'batch_size': 32,\n    'data_augmentation': False,\n    'epochs': 15,\n    'optimizer_type': 'Adam'\n}\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nscaler = amp.GradScaler(enabled=device.type == 'cuda')\n\n# Define transforms based on config\ndef get_transforms(data_augmentation, is_training=True):\n    \"\"\"Get the appropriate transforms based on whether we're training and using augmentation.\"\"\"\n    if is_training and data_augmentation:\n        return transforms.Compose([\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomRotation(degrees=15),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n    else:\n        return transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n# Determine filter sizes based on strategy\nbase_filter = best_config['base_filter']\nif best_config['filter_strategy'] == 'same':\n    filters = [base_filter] * 5\nelif best_config['filter_strategy'] == 'doubling':\n    filters = [base_filter * (2 ** i) for i in range(5)]\nelif best_config['filter_strategy'] == 'halving':\n    filters = [base_filter * (2 ** i) for i in reversed(range(5))]\n\n# Initialize model with best config\n#from cnn import SimpleCNN  # Make sure this import works\nmodel = SimpleCNN(\n    num_classes=10,\n    kernel_size=best_config['kernel_sizes'],\n    no_kernels=filters,\n    fc1_size=best_config['fc_size'],\n    conv_activation=best_config['activation'],\n    use_batch_norm=best_config['batch_norm'],\n    dropout=best_config['dropout']\n)\nmodel = model.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\nif best_config['optimizer_type'] == 'Adam':\n    optimizer = optim.Adam(model.parameters(), lr=best_config['learning_rate'], weight_decay=1e-4)\nelif best_config['optimizer_type'] == 'Nadam':\n    optimizer = optim.NAdam(model.parameters(), lr=best_config['learning_rate'], weight_decay=1e-4)\n\n# Load and split dataset\ndataset = datasets.ImageFolder(\n    root=data_path,\n    transform=get_transforms(best_config['data_augmentation'], is_training=True)\n)\n\n# Calculate split sizes (80% train, 20% validation)\nval_split = 0.2\ndataset_size = len(dataset)\nval_size = int(val_split * dataset_size)\ntrain_size = dataset_size - val_size\n\n# Split dataset\ntrain_dataset, val_dataset = random_split(\n    dataset, [train_size, val_size],\n    generator=torch.Generator().manual_seed(42)  # For reproducibility\n)\n\n# Update validation transform\nval_dataset.dataset.transform = get_transforms(False, is_training=False)\n\n# Create data loaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=best_config['batch_size'],\n    shuffle=True,\n    pin_memory=True,\n    num_workers=4\n)\n\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=best_config['batch_size'],\n    shuffle=False,\n    pin_memory=True,\n    num_workers=4\n)\n\n# Define function to run an epoch\ndef run_epoch(model, dataloader, criterion, optimizer, device, scaler, is_training=True):\n    \"\"\"Run one epoch of training or validation.\"\"\"\n    total_loss = 0\n    total = 0\n    correct = 0\n    \n    for images, labels in dataloader:\n        images, labels = images.to(device), labels.to(device)\n        \n        # Forward pass with autocast for mixed precision\n        with amp.autocast(device_type=device.type, enabled=scaler.is_enabled() and is_training):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n        \n        # Backward pass and optimization (only during training)\n        if is_training:\n            optimizer.zero_grad()\n            # Use scaler for mixed precision gradient scaling\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        \n        # Calculate accuracy\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        # Accumulate loss\n        total_loss += loss.item() * images.size(0)\n    \n    # Calculate average loss and accuracy\n    avg_loss = total_loss / total\n    accuracy = 100 * correct / total\n    \n    return avg_loss, accuracy\n\n# Train the model\nprint(\"Starting training with best configuration...\")\nbest_val_accuracy = 0\nmodel_save_path = \"best_model.pth\"\n\nfor epoch in range(best_config['epochs']):\n    # Training phase\n    model.train()\n    train_loss, train_accuracy = run_epoch(model, train_loader, criterion, optimizer, device, scaler, is_training=True)\n    \n    # Validation phase\n    model.eval()\n    with torch.no_grad():\n        val_loss, val_accuracy = run_epoch(model, val_loader, criterion, optimizer, device, scaler, is_training=False)\n    \n    # Save best model\n    if val_accuracy > best_val_accuracy:\n        best_val_accuracy = val_accuracy\n        torch.save(model.state_dict(), model_save_path)\n        print(f\"New best model saved with validation accuracy: {val_accuracy:.2f}%\")\n    \n    print(f\"Epoch [{epoch + 1}/{best_config['epochs']}], \"\n          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n\nprint(f\"Training completed. Best validation accuracy: {best_val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T13:52:27.274092Z","iopub.execute_input":"2025-04-19T13:52:27.274375Z","iopub.status.idle":"2025-04-19T14:06:18.389448Z","shell.execute_reply.started":"2025-04-19T13:52:27.274350Z","shell.execute_reply":"2025-04-19T14:06:18.388529Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nStarting training with best configuration...\nNew best model saved with validation accuracy: 30.77%\nEpoch [1/15], Train Loss: 2.1040, Train Accuracy: 25.16%, Val Loss: 1.9575, Val Accuracy: 30.77%\nNew best model saved with validation accuracy: 33.22%\nEpoch [2/15], Train Loss: 1.9290, Train Accuracy: 32.08%, Val Loss: 1.9082, Val Accuracy: 33.22%\nNew best model saved with validation accuracy: 33.72%\nEpoch [3/15], Train Loss: 1.8398, Train Accuracy: 35.35%, Val Loss: 1.9084, Val Accuracy: 33.72%\nNew best model saved with validation accuracy: 36.37%\nEpoch [4/15], Train Loss: 1.7504, Train Accuracy: 38.42%, Val Loss: 1.8148, Val Accuracy: 36.37%\nEpoch [5/15], Train Loss: 1.6699, Train Accuracy: 41.88%, Val Loss: 1.8153, Val Accuracy: 36.12%\nNew best model saved with validation accuracy: 39.77%\nEpoch [6/15], Train Loss: 1.5834, Train Accuracy: 45.00%, Val Loss: 1.7284, Val Accuracy: 39.77%\nEpoch [7/15], Train Loss: 1.4952, Train Accuracy: 47.86%, Val Loss: 1.8212, Val Accuracy: 36.87%\nEpoch [8/15], Train Loss: 1.3996, Train Accuracy: 51.67%, Val Loss: 1.7750, Val Accuracy: 38.37%\nNew best model saved with validation accuracy: 42.92%\nEpoch [9/15], Train Loss: 1.3085, Train Accuracy: 55.21%, Val Loss: 1.6529, Val Accuracy: 42.92%\nEpoch [10/15], Train Loss: 1.2053, Train Accuracy: 59.23%, Val Loss: 1.7716, Val Accuracy: 39.92%\nEpoch [11/15], Train Loss: 1.1195, Train Accuracy: 61.51%, Val Loss: 1.7201, Val Accuracy: 41.27%\nEpoch [12/15], Train Loss: 1.0003, Train Accuracy: 66.04%, Val Loss: 1.7755, Val Accuracy: 41.27%\nEpoch [13/15], Train Loss: 0.8946, Train Accuracy: 70.55%, Val Loss: 1.7437, Val Accuracy: 42.67%\nEpoch [14/15], Train Loss: 0.7735, Train Accuracy: 75.80%, Val Loss: 1.7572, Val Accuracy: 42.52%\nNew best model saved with validation accuracy: 43.12%\nEpoch [15/15], Train Loss: 0.6488, Train Accuracy: 80.01%, Val Loss: 1.8376, Val Accuracy: 43.12%\nTraining completed. Best validation accuracy: 43.12%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Load the test dataset\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_dataset = datasets.ImageFolder(\n    root=test_data_path,\n    transform=test_transform\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=best_config['batch_size'],\n    shuffle=False,\n    pin_memory=True,\n    num_workers=4\n)\n\n# Get class names\nclass_names = test_dataset.classes\nprint(f\"Classes: {class_names}\")\n\n# Load the best model\nmodel_save_path=\"/kaggle/working/best_model.pth\"\nmodel.load_state_dict(torch.load(model_save_path))\nmodel.eval()\n\n# Evaluate on test set\ndef evaluate_model(model, dataloader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    all_preds = []\n    all_labels = []\n    all_images = []\n    \n    with torch.no_grad():\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            # Store predictions, labels, and images for visualization\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            # Convert images to numpy for visualization (only store a subset if needed)\n            for img in images.cpu().numpy():\n                all_images.append(img)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    accuracy = 100 * correct / total\n    return accuracy, all_preds, all_labels, all_images\n\n# Run the evaluation\ntest_accuracy, predictions, true_labels, test_images = evaluate_model(model, test_loader, device)\nprint(f\"Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:06:55.503708Z","iopub.execute_input":"2025-04-19T14:06:55.504028Z","iopub.status.idle":"2025-04-19T14:07:05.990669Z","shell.execute_reply.started":"2025-04-19T14:06:55.504000Z","shell.execute_reply":"2025-04-19T14:07:05.989859Z"}},"outputs":[{"name":"stdout","text":"Classes: ['Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/1960726611.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_save_path))\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 44.40%\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\nimport numpy as np\nfrom PIL import Image, ImageDraw, ImageFont\ndef create_creative_prediction_grid(images, preds, labels, class_names, rows=10, cols=3):\n\n\n    # Normalize stats\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    num_samples = rows * cols\n\n    # Select correct/incorrect\n    correct = [i for i, (p, l) in enumerate(zip(preds, labels)) if p == l]\n    incorrect = [i for i, (p, l) in enumerate(zip(preds, labels)) if p != l]\n    n_incorrect = min(num_samples // 3, len(incorrect))\n    n_correct = num_samples - n_incorrect\n\n    selected = list(np.random.choice(correct, n_correct, replace=False)) + \\\n               list(np.random.choice(incorrect, n_incorrect, replace=False))\n    np.random.shuffle(selected)\n\n    if len(selected) < num_samples:\n        remaining = num_samples - len(selected)\n        pool = [i for i in range(len(images)) if i not in selected]\n        selected += list(np.random.choice(pool, remaining, replace=False))\n\n    # Layout settings\n    image_size = 180\n    padding_x = 40\n    padding_y = 30\n    margin = 60\n    text_height = 45\n    cell_width = image_size + padding_x\n    cell_height = image_size + text_height + padding_y\n\n    grid_width = cols * cell_width + 2 * margin\n    grid_height = rows * cell_height + 2 * margin + 80  # + title\n\n    grid_image = Image.new('RGB', (grid_width, grid_height), color=(255, 255, 255))\n    draw = ImageDraw.Draw(grid_image)\n\n    try:\n        font = ImageFont.truetype(\"Arial.ttf\", 18)\n        small_font = ImageFont.truetype(\"Arial.ttf\", 14)\n    except IOError:\n        font = ImageFont.load_default()\n        small_font = ImageFont.load_default()\n\n    # Title\n    title = \"Test Set Predictions (Best CNN)\"\n    title_x = (grid_width - draw.textlength(title, font=font)) // 2\n    draw.text((title_x, 20), title, fill=(0, 0, 0), font=font)\n\n    model_info = f\"{best_config['filter_strategy'].capitalize()} filters | {best_config['activation']} | Dropout={best_config['dropout']}\"\n    draw.text((margin, 50), model_info, fill=(60, 60, 60), font=small_font)\n    draw.text((margin, 70), f\"Test Accuracy: {test_accuracy:.2f}%\", fill=(60, 60, 60), font=small_font)\n\n    # Draw each image block\n    for idx, img_idx in enumerate(selected):\n        img = images[img_idx].transpose(1, 2, 0) * std + mean\n        img = np.clip(img, 0, 1)\n        img = (img * 255).astype(np.uint8)\n        img_pil = Image.fromarray(img).resize((image_size, image_size), Image.BICUBIC)\n\n        row, col = divmod(idx, cols)\n        x = margin + col * cell_width\n        y = margin + row * cell_height + 80\n\n        pred = preds[img_idx]\n        label = labels[img_idx]\n        is_correct = pred == label\n\n        bg_color = (235, 255, 235) if is_correct else (255, 235, 235)\n        draw.rectangle([x - 8, y - 8, x + image_size + 8, y + image_size + text_height + 8], fill=bg_color, outline=(200, 200, 200))\n\n        grid_image.paste(img_pil, (x, y))\n\n        # Text\n        draw.text((x, y + image_size + 5), f\"True: {class_names[label]}\", fill=(0, 100, 0) if is_correct else (150, 0, 0), font=small_font)\n        draw.text((x, y + image_size + 22), f\"Pred: {class_names[pred]}\", fill=(0, 0, 100), font=small_font)\n\n    return grid_image\ngrid_image = create_creative_prediction_grid(test_images, predictions, true_labels, class_names)\ngrid_image.save(\"prediction_grid.png\")\nprint(\"10×3 prediction grid saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T14:07:25.973767Z","iopub.execute_input":"2025-04-19T14:07:25.974112Z","iopub.status.idle":"2025-04-19T14:07:26.493351Z","shell.execute_reply.started":"2025-04-19T14:07:25.974083Z","shell.execute_reply":"2025-04-19T14:07:26.492618Z"}},"outputs":[{"name":"stdout","text":"10×3 prediction grid saved!\n","output_type":"stream"}],"execution_count":9}]}